{"neutrino": {"2312.02797": "2023-12-05, **Two Texture Zeros for Dirac Neutrinos in a Diagonal charged Lepton basis**, Yessica Lenis et.al., [2312.02797v1](http://arxiv.org/abs/2312.02797v1)\n\n A systematic study of the neutrino mass matrix $M\\_\\nu$ with two texture zeros in a basis where the charged leptons are diagonal, and under the assumption that neutrinos are Dirac particles, is carried through in detail. Our study is done without any approximation, first analytically and then numerically. Current neutrino oscillation data are used in our analysis. Phenomenological implications of $M\\_\\nu$ on the lepton CP violation and neutrino mass spectrum are explored.\n\n", "2312.02789": "2023-12-05, **Measurement of the Z boson invisible width at $\\sqrt{s}=13$ TeV with the ATLAS detector**, ATLAS Collaboration et.al., [2312.02789v1](http://arxiv.org/abs/2312.02789v1)\n\n A measurement of the invisible width of the $Z$ boson using events with jets and missing transverse momentum is presented using 37 $\\mbox{fb\\(^{-1}\\)}$ of 13 TeV proton-proton data collected by the ATLAS detector in 2015 and 2016. The ratio of $Z\\rightarrow \\textrm{inv}$ to $Z\\rightarrow\\ell\\ell$ events, where inv refers to non-detected particles and $\\ell$ is either an electron or a muon, is measured and corrected for detector effects. Events with at least one energetic central jet with $p\\_{\\textrm{T}} \\geq 110$ GeV are selected for both the $Z\\rightarrow \\textrm{inv}$ and $Z\\rightarrow\\ell\\ell$ final states to obtain a similar phase space in the ratio. The invisible width is measured to be $506\\pm2 \\textrm{ (stat.)} \\pm12 \\textrm{ (syst.)}$ MeV and is the single most precise recoil-based measurement. The result is in agreement with the most precise determination from LEP and the Standard Model prediction based on three neutrino generations.\n\n"}, "dark matter": {"2312.02972": "2023-12-05, **PROSPECT: A profile likelihood code for frequentist cosmological parameter inference**, Emil Brinch Holm et.al., [2312.02972v1](http://arxiv.org/abs/2312.02972v1)\n\n Cosmological parameter inference has been dominated by the Bayesian approach for the past two decades, primarily due to its computational efficiency. However, the Bayesian approach involves integration of the posterior probability and therefore depends on both the choice of model parametrisation and the choice of prior on the model parameter space. In some cases, this can lead to conclusions which are driven by choice of parametrisation and priors rather than by data. The profile likelihood method provides a complementary frequentist tool which can be used to investigate this effect.   In this paper, we present the code PROSPECT for computing profile likelihoods in cosmology. We showcase the code using a phenomenological model for converting dark matter into dark radiation that suffers from large volume effects and prior dependence. PROSPECT is compatible with both cobaya and MontePython, and is publicly available at https://github.com/AarhusCosmology/prospect\\_public.\n\n", "2312.02968": "2023-12-05, **Fast particle-mesh code for Milgromian dynamics**, P. M. Visser et.al., [2312.02968v1](http://arxiv.org/abs/2312.02968v1)\n\n Modified Newtonian dynamics (MOND) is a promising alternative to dark matter. To further test the theory, there is a need for fluid- and particle-dynamics simulations. The force in MOND is not a direct particle-particle interaction, but derives from a potential for which a nonlinear partial differential equation (PDE) needs to be solved. Normally, this makes the problem of simulating dynamical evolution computationally expensive. We intend to develop a fast particle-mesh (PM) code for MOND (the AQUAL formalism). We transformed the nonlinear equation for MOND into a system of linear PDEs plus one algebraic equation. An iterative scheme with the fast Fourier transform (FFT) produces successively better numerical approximations. The algorithm was tested for dynamical systems in MOND where analytical solutions are known: the two-body problem, a body with a circular ring, and a spherical distribution of particles in thermal equilibrium in the self-consistent potential. The PM code can accurately calculate the forces at subpixel scale and reproduces the analytical solutions. Four iterations are required for the potential, but when the spatial steps are small compared to the kernel width, one iteration is suffices. The use of a smoothing kernel for the accelerations is inevitable in order to eliminate the self-gravity of the point particles. Our PDE solver is $15$ to $42$ times as slow as a standard Poisson solver. However, the smoothing and particle propagation takes up most of the time above one particle per $10^3$ pixels. The FFTs, the smoothing, and the propagation part in the code can all be parallelized.\n\n", "2312.02707": "2023-12-05, **SKA Sensitivity to Sub-GeV Dark Matter Decay: Synchrotron Radio Emissions in White Dwarf Magnetospheres**, Kenji Kadota et.al., [2312.02707v1](http://arxiv.org/abs/2312.02707v1)\n\n We investigate the potential of the Square Kilometre Array (SKA) in detecting synchrotron radiation emitted from the decay of sub-GeV dark matter (dark matter with masses below the GeV scale) in the presence of strong magnetic fields. As a concrete setup, we consider scenarios where the magnetosphere of a magnetic white dwarf overlaps with dense dark matter environments, such as those surrounding a primordial black hole. Our study reveals that the encounters of compact objects such as white dwarfs and black holes offer a promising avenue for upcoming radio telescopes to probe the properties of light dark matter, which has been less explored compared with more conventional heavier (masses above the GeV scale) dark matter.\n\n", "2312.02552": "2023-12-05, **Gluon condensation: from nucleon to Galactic center**, Wei Zhu et.al., [2312.02552v1](http://arxiv.org/abs/2312.02552v1)\n\n The Galactic Center Excess (GCE), one of the most remarkable discoveries by Fermi-LAT, has prompted extensive exploration over the past decade, often attributed to dark matter or millisecond pulsars. This work proposes a novel interpretation on the origin of the GCE, focusing on the observed spectral shape. Protons are accelerated at the Galactic center and collide with the neutron cluster on the surface of the non-rotating neutron stars. Due to the gluon condensation in nucleons, these collisions produce a large number of mesons, which have reached to the saturation state and subsequently generate the broken power law in the gamma ray spectra. We explained the spectral shape of GCE using the gluon condensation and an assumption of existing the non-rotating neutron stars at the Galactic center. This example of the gluon condensation mechanism not only expands the applications of the hadronic scenario in the cosmic gamma ray spectra but also provides a new evidence of the gluon condensation.\n\n", "2312.02511": "2023-12-05, **Cosmological constraints from the EFT power spectrum and tree-level bispectrum of 21cm intensity maps**, Liantsoa F. Randrianjanahary et.al., [2312.02511v1](http://arxiv.org/abs/2312.02511v1)\n\n We explore the information content of 21cm intensity maps in redshift space using the 1-loop Effective Field Theory power spectrum model and the bispectrum at tree level. The 21cm signal contains signatures of dark matter, dark energy and the growth of large-scale structure in the Universe. These signatures are typically analyzed via the 2-point correlation function or power spectrum. However, adding the information from the 3-point correlation function or bispectrum will be crucial to exploiting next-generation intensity mapping experiments. The bispectrum could offer a unique opportunity to break key parameter degeneracies that hinder the measurement of cosmological parameters and improve on the precision. We use a Fisher forecast analysis to estimate the constraining power of the HIRAX survey on cosmological parameters, dark energy and modified gravity.\n\n", "2312.02466": "2023-12-05, **Merger Tree-based Halo/Galaxy Matching Between Cosmological Simulations with Different Resolutions: Galaxy-by-galaxy Resolution Study and the Machine Learning-based Correction**, Minyong Jung et.al., [2312.02466v1](http://arxiv.org/abs/2312.02466v1)\n\n We introduce a novel halo/galaxy matching technique between two cosmological simulations with different resolutions, which utilizes the positions and masses of halos along their subhalo merger tree. With this tool, we conduct a study of resolution biases through the galaxy-by-galaxy inspection of a pair of simulations that have the same simulation configuration but different mass resolutions, utilizing a suite of IllustrisTNG simulations to assess the impact on galaxy properties. We find that, with the subgrid physics model calibrated for TNG100-1, subhalos in TNG100-1 (high resolution) have $\\lesssim0.5$ dex higher stellar masses than their counterparts in the TNG100-2 (low-resolution). It is also discovered that the subhalos with $M\\_{\\mathrm{gas}}\\sim10^{8.5}{\\rm M}\\_\\odot$ in TNG100-1 have $\\sim0.5$ dex higher gas mass than those in TNG100-2. The mass profiles of the subhalos reveal that the dark matter masses of low-resolution subhalos are $\\sim0.6$ times lower within 2 kpc, near the resolution limit. The differences in stellar mass and hot gas mass are most pronounced in the central region. We exploit machine learning to build a correction mapping for the physical quantities of subhalos from low- to high-resolution simulations (TNG300-1 and TNG100-1), which enables us to find an efficient way to compile a high-resolution galaxy catalog even from a low-resolution simulation. Our tools can easily be applied to other large cosmological simulations, testing and mitigating the resolution biases of their numerical codes and subgrid physics models.\n\n"}, "supernova": {"2312.02835": "2023-12-05, **Design and performance of a Collimated Beam Projector for telescope transmission measurement using a broadband light source**, K. Sommer et.al., [2312.02835v1](http://arxiv.org/abs/2312.02835v1)\n\n Type Ia supernovae are one such cosmological probe to study dark energy, for which the dominant source of systematic uncertainties is the accuracy of the photometric calibration. To address this, recent advancements introduce Collimated Beam Projectors (CBP), aiming to enhance calibration by precisely measuring a telescope's throughput as a function of wavelength. This work describes the performance of a prototype portable CBP. The experimental setup consists of a broadband Xenon light source replacing a more customary but much more demanding high-power laser source, coupled with a monochromator emitting light inside an integrating sphere monitored with a photodiode and a spectrograph. Light is injected at the focus of the CBP telescope projecting a collimated beam onto a solar cell whose quantum efficiency has been obtained by comparison with a NIST-calibrated photodiode. The throughput and signal-to-noise ratio achieved by comparing the photocurrent signal in the CBP photodiode to the one in the solar cell are computed. We prove that the prototype, in its current state of development, is capable of achieving 1.2 per cent and 2.3 per cent precision on the integrated g and r bands of the ZTF photometric filter system respectively, in a reasonable amount of integration time. Central wavelength determination accuracy is kept below ~0.91 nm and ~0.58 nm for g and r bands, respectively. The expected photometric uncertainty caused by filter throughput measurement is approximately 5 mmag on the zero-point magnitude. Several straightforward improvement paths are discussed to upgrade the current setup.\n\n", "2312.02411": "2023-12-05, **Variable Chaplygin Gas: Contraining parameters using FRBs**, Geetanjali Sethi et.al., [2312.02411v1](http://arxiv.org/abs/2312.02411v1)\n\n We investigate the cosmological constraints on the Variable Chaplygin gas model with the latest observational data from the Fast Radio Bursts and SNeIa (Pantheon+SHOES). The Variable Chaplygin gas model is shown to be compatible with Type Ia Supernovae and Fast Radio Burts. We have obtained tighter constraints on cosmological parameters Bs and n, using the the FRB data set. By using the Markov chain Monte Carlo (MCMC) method on the SNeIa data set, we obtain Bs=0.1956 +- 0.1047 , n= 1.3581 +- 1.1678 and H0= 70.3902 +- 0.6381 and we obtain Bs= 0.1780 +-0.1069 , n= 1.2633+- 1.2433 and H0=70.397 +- 0.6597 from the FRB data set. We are able to get a good agreement between the H0 values from the two data sets.\n\n"}}